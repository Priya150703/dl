{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "An autoencoder is a special type of neural network that is trained to copy its input to its output. For example, given an image of a handwritten digit, an autoencoder first encodes the image into a lower dimensional latent representation, then decodes the latent representation back to an image. An autoencoder learns to compress the data while minimizing the reconstruction error.\n",
        "\n",
        "To learn more about autoencoders, please consider reading chapter 14 from Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville."
      ],
      "metadata": {
        "id": "7zVrr4XHnYXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import TensorFlow and other libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "aR4OSzwjnbtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErGrTnWHoUYl"
      },
      "source": [
        "##  Anomaly detection\n",
        "\n",
        "## Overview\n",
        "\n",
        "\n",
        "In this example, you will train an autoencoder to detect anomalies on the [ECG5000 dataset](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000). This dataset contains 5,000 [Electrocardiograms](https://en.wikipedia.org/wiki/Electrocardiography), each with 140 data points. You will use a simplified version of the dataset, where each example has been labeled either `0` (corresponding to an abnormal rhythm), or `1` (corresponding to a normal rhythm). You are interested in identifying the abnormal rhythms.\n",
        "\n",
        "Note: This is a labeled dataset, so you could phrase this as a supervised learning problem. The goal of this example is to illustrate anomaly detection concepts you can apply to larger datasets, where you do not have labels available (for example, if you had many thousands of normal rhythms, and only a small number of abnormal rhythms).\n",
        "\n",
        "How will you detect anomalies using an autoencoder? Recall that an autoencoder is trained to minimize reconstruction error. You will train an autoencoder on the normal rhythms only, then use it to reconstruct all the data. Our hypothesis is that the abnormal rhythms will have higher reconstruction error. You will then classify a rhythm as an anomaly if the reconstruction error surpasses a fixed threshold."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load ECG data\n",
        "# Download the dataset\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
        "raw_data = dataframe.values\n",
        "dataframe.tail()"
      ],
      "metadata": {
        "id": "-cR04bfzofFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The last element contains the labels\n",
        "labels = raw_data[:, -1] #extracts the last column of the raw_data array\n",
        "\n",
        "# The other data points are the electrocadriogram data\n",
        "data = raw_data[:, 0:-1] #extracts all columns of the raw_data array except the last one\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=21\n",
        ")"
      ],
      "metadata": {
        "id": "EKI1C10oonGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = tf.reduce_min(train_data) # finding the smallest value among all the features in the training dataset.\n",
        "max_val = tf.reduce_max(train_data) # finding the largest value among all the features in the training dataset.\n",
        "\n",
        "#Normalize the data to [0,1].\n",
        "train_data = (train_data - min_val) / (max_val - min_val) #Each feature value is subtracted by the minimum value (min_val) and then divided by\n",
        "test_data = (test_data - min_val) / (max_val - min_val)   #the range (max_val - min_val). This ensures that all features are on a similar scale\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)  #data is represented as 32-bit floating-point numbers,\n",
        "test_data = tf.cast(test_data, tf.float32)    #which is the default data type for many TensorFlow operations"
      ],
      "metadata": {
        "id": "DTwKcFDBoqHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will train the autoencoder using only the normal rhythms, which are labeled in this dataset as 1. Separate the normal rhythms from the abnormal rhythms."
      ],
      "metadata": {
        "id": "JYa_uOqxpSB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_labels.astype(bool) #convert array to boolean data type to treat labels as binary(normal or anomalous)\n",
        "test_labels = test_labels.astype(bool)   #normal instance (True or 1) , anomalous instance (False or 0)\n",
        "\n",
        "normal_train_data = train_data[train_labels] #containing only the instances labeled as True in train_labels. These instances are considered \"normal\"\n",
        "normal_test_data = test_data[test_labels]  #containing only the instances labeled as True in test_labels. These instances are considered \"normal\"\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]  #create subsets of the train_data and test_data arrays containing instances labeled as False\n",
        "anomalous_test_data = test_data[~test_labels] #in train_labels and test_labels, respectively. These instances are considered \"anomalous\" or abnormal"
      ],
      "metadata": {
        "id": "fmm5sc66pV_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a normal ECG."
      ],
      "metadata": {
        "id": "LRt18MchpZqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), normal_train_data[0])\n",
        "#generates an array from 0 to 139, representing the x-axis values. normal_train_data[0] contains the y-axis values\n",
        "plt.title(\"A Normal ECG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yQr8Ad-lpays"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot an anomalous ECG.\n",
        "plt.grid()\n",
        "plt.plot(np.arange(140), anomalous_train_data[0])\n",
        "plt.title(\"An Anomalous ECG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lmqa5HxerPs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the model\n",
        "class AnomalyDetector(Model):   #creating a custom model using TensorFlow and Keras for anomaly detection\n",
        "  def __init__(self):      #initializes the architecture of the anomaly detection model\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Dense(32, activation=\"relu\"), #TensorFlow sequential model is defined as the encoder part of the anomaly detection model.\n",
        "      layers.Dense(16, activation=\"relu\"), #The encoder consists of three dense layers with ReLU activation functions.\n",
        "      layers.Dense(8, activation=\"relu\")]) #The number of neurons in each layer is 32, 16, and 8, respectively.\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(140, activation=\"sigmoid\")]) #final layer uses the sigmoid activation function to output values between 0 and 1.\n",
        "\n",
        "  def call(self, x):t\n",
        "                                      #The call method defines the forward pass of the anomaly detection model.\n",
        "    encoded = self.encoder(x)         #It takes an input tensor x and passes it through the encoder and decoder,\n",
        "    decoded = self.decoder(encoded)   #returning the reconstructed output.\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()  # instance is created which  represents the anomaly detection model"
      ],
      "metadata": {
        "id": "6Tmc0sj1rTnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "# Adaptive Moment Estimation optimization algorithm to be used during training dynamically adjusts the learning rate for each parameter\n",
        "#Mean Absolute Error loss function bsolute difference between the predicted values and the actual values and then averages these differences"
      ],
      "metadata": {
        "id": "nHzjjSR6rXw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Notice that the autoencoder is trained using only the normal ECGs, but is evaluated using the full test set."
      ],
      "metadata": {
        "id": "xbjdolMTra0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(normal_train_data, normal_train_data,#input data and target data are same, as model aims to reconstruct the input data\n",
        "          epochs=20,  # number of times the entire training dataset will be passed forward and backward through the neural network\n",
        "          batch_size=512,  #model's weights are updated after processing each batch of 512 samples.\n",
        "          validation_data=(test_data, test_data), #specifies the validation data to be used during training\n",
        "          shuffle=True) #Indicates that the training data should be shuffled before each epoch"
      ],
      "metadata": {
        "id": "1IEn69uRre1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "#line plots the training loss values,history.history[\"loss\"] contains the training loss values recorded during each epoch\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "SGL_DaoKrhxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will soon classify an ECG as anomalous if the reconstruction error is greater than one standard deviation from the normal training examples. First, let's plot a normal ECG from the training set, the reconstruction after it's encoded and decoded by the autoencoder, and the reconstruction error."
      ],
      "metadata": {
        "id": "QSmmkT9srnfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(normal_test_data).numpy()\n",
        "#passes the normal test instances through the encoder part of the autoencoder model and obtains the encoded representations,\n",
        "#.numpy() method converts the TensorFlow tensor to a NumPy array.\n",
        "\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
        "#takes the encoded data and passes it through the decoder part of the autoencoder model to obtain the reconstructed (decoded) data\n",
        "#.numpy() converts the TensorFlow tensor to a NumPy array\n",
        "\n",
        "plt.plot(normal_test_data[0], 'b') #plots the original normal test data (input) in blue color\n",
        "plt.plot(decoded_data[0], 'r')  #plots the reconstructed data (output of the decoder) in red  color.\n",
        "plt.fill_between(np.arange(140), decoded_data[0], normal_test_data[0], color='lightcoral')\n",
        "#fills the area betn original data & reconstructed data with a light coral color\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A5KEMhcrrkYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a similar plot, this time for an anomalous test example."
      ],
      "metadata": {
        "id": "Dsy7LfJ_rt_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#same as above but is done on anomalous data\n",
        "encoded_data = autoencoder.encoder(anomalous_test_data).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
        "\n",
        "plt.plot(anomalous_test_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], anomalous_test_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F2f4abQYrucT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detect anomalies by calculating whether the reconstruction loss is greater than a fixed threshold. In this tutorial, you will calculate the mean average error for normal examples from the training set, then classify future examples as anomalous if the reconstruction error is higher than one standard deviation from the training set."
      ],
      "metadata": {
        "id": "InzRZVmLry1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the reconstruction error on normal ECGs from the training set\n",
        "reconstructions = autoencoder.predict(normal_train_data)\n",
        "#line uses the trained autoencoder model to predict the reconstructed data (reconstructions) for the normal training data\n",
        "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)#mean absolute error loss betn original normal training data & its reconstructions\n",
        "plt.hist(train_loss[None,:], bins=50) # line creates a histogram of the calculated training loss values\n",
        "plt.xlabel(\"Train loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SwUtYrATr19a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh-3ChEF5hog"
      },
      "source": [
        "Choose a threshold value that is one standard deviations above the mean."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.mean(train_loss) + np.std(train_loss)\n",
        "print(\"Threshold: \", threshold)\n",
        "# calculates the threshold value. np.mean(train_loss) computes the mean of the training loss values, and np.std(train_loss)\n",
        "# calculates the standard deviation of the training loss values."
      ],
      "metadata": {
        "id": "nsojMUwvr_E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: There are other strategies you could use to select a threshold value above which test examples should be classified as anomalous, the correct approach will depend on your dataset.\n",
        "\n",
        "If you examine the reconstruction error for the anomalous examples in the test set, you'll notice most have greater reconstruction error than the threshold. By varing the threshold, you can adjust the precision and recall of your classifier."
      ],
      "metadata": {
        "id": "gDNNroXrsRlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same as normal data above\n",
        "reconstructions = autoencoder.predict(anomalous_test_data) #predict the reconstructed data for the anomalous test data\n",
        "test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)\n",
        "\n",
        "plt.hist(test_loss[None, :], bins=50)\n",
        "plt.xlabel(\"Test loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eDeNsi79rwSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classify an ECG as an anomaly if the reconstruction error is greater than the threshold."
      ],
      "metadata": {
        "id": "S9Lnne_8sZl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data, threshold):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold)\n",
        "#predicts the reconstructions using the model, calculates the mean absolute error (MAE) loss between the original data and the reconstructions,\n",
        "#and compares the loss values with the threshold\n",
        "#Parameters:\n",
        "#model: Anomaly detection model (autoencoder in this case).\n",
        "#data: Input data (either normal or anomalous).\n",
        "#threshold: Threshold value for classifying anomalies.\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, predictions)))\n",
        "#function takes predicted values (predictions) and ground truth labels (labels) and prints accuracy, precision, and recall scores to\n",
        "#evaluate the model's performance.\n",
        "#Parameters:\n",
        "#predictions: Predicted labels indicating anomalies (True) or normals (False).\n",
        "#labels: Ground truth labels indicating anomalies (True) or normals (False).\n"
      ],
      "metadata": {
        "id": "fttPz9VDsaHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(autoencoder, train_data, threshold)\n",
        "print_stats(preds, train_labels)\n",
        "#calls the predict function with the autoencoder model, training data (train_data), and the calculated threshold.\n",
        "#It generates predictions for the training data"
      ],
      "metadata": {
        "id": "pUOOuWICxDsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#same as above\n",
        "preds = predict(autoencoder, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ],
      "metadata": {
        "id": "rnYh_VciscDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}